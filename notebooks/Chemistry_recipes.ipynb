{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cathedral-explosion",
   "metadata": {},
   "source": [
    "# CheMastery: Identify information in chemical recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import chemdataextractor\n",
    "from chemdataextractor import Document\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = '/Users/Viktoria/Desktop/Chemistry_project'\n",
    "os.chdir(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('exercise_experimentals.txt', 'rb')\n",
    "doc = Document.from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc), ' ', type(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-melbourne",
   "metadata": {},
   "source": [
    "## Question 1. What was added to what?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-avatar",
   "metadata": {},
   "source": [
    "### Step 1. Get the sentences of the text up until the last occurrence of addition. <br> Step 2. Get the named entities that stand for the ingredients. <br> Step 3. Get the syntactic position of the ingredients to find out 'what was added to what'. In 'X was added to Y' X is the subject, Y is the object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of strings (recipes) which contains the texts of each recipe up until the last occurrence of the phrase that contains the addition\n",
    "\n",
    "recipes=[]\n",
    "\n",
    "for i in range(0, len(doc)):\n",
    "    \n",
    "    paragraph=[]\n",
    "    tracker=[]\n",
    "    \n",
    "    for sentence in doc[i].sentences:\n",
    "        text=str(sentence).lower()\n",
    "        paragraph.append(text)\n",
    "        \n",
    "        #check if the addition phrase is present\n",
    "        if 'add' in text or 'addition' in text:\n",
    "            tracker.append(1)\n",
    "        else:\n",
    "            tracker.append(0)\n",
    "            \n",
    "    #consider the text until the last occurrence of the 'add' phrase\n",
    "    paragraph = paragraph[0:np.max(np.nonzero(tracker))+1]    \n",
    "    paragraph = ' '.join([p for p in paragraph])\n",
    "    recipes.append(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of all the chemical elements in each recipe\n",
    "\n",
    "entities=[]\n",
    "for i in range(len(doc.cems)):\n",
    "    entities.append(str(doc.cems[i]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for each recipe (indices) with the name of the entity, starting position, ending position. \n",
    "# These dictionaries will be passed to spacy to get the syntax of the sentences.\n",
    "\n",
    "tagged_entities = []\n",
    "\n",
    "for recipe in recipes:\n",
    "    \n",
    "    indices={}\n",
    "    \n",
    "    #check which entities appear in the text\n",
    "    for entity in entities:\n",
    "        \n",
    "        #look for the entity \n",
    "        if entity in recipe:\n",
    "            \n",
    "            #get the start & end position and add it to the dict\n",
    "            start = recipe.index(entity)\n",
    "            end = recipe.index(entity)+len(entity)\n",
    "            indices[entity]=start, end\n",
    "            \n",
    "    #only match the full chemical name, not if e.g. the word 'h2o' is contained in a longer name\n",
    "    keys = list(indices.keys())\n",
    "    for word in keys: \n",
    "        if sum(word in k for k in keys) > 1: #more than 1 occurrences \n",
    "            indices.pop(word) #pop the short word that is contained by other words\n",
    "    \n",
    "    \n",
    "    tagged_entities.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the named entities to spacy, then get the information which one was the subject and which one the object of the sentence\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") # load a new spacy model\n",
    "\n",
    "db = DocBin() # create a DocBin object\n",
    "corpora = [] # these will be the syntactically tagged recipes\n",
    "\n",
    "for i,v in enumerate(recipes):\n",
    "\n",
    "    indices=tagged_entities[i]\n",
    "\n",
    "    spacy_doc = nlp(recipes[i]) # create doc object from text\n",
    "    ents = []\n",
    "    \n",
    "    for (key,value) in indices.items(): # add character indexes\n",
    "        span = spacy_doc.char_span(value[0], value[1], label=key, alignment_mode=\"expand\")\n",
    "        \n",
    "        if span is None:\n",
    "            print('none')\n",
    "        else:\n",
    "            ents.append(span)\n",
    "          \n",
    "    spacy_doc.ents = ents # label the text with the ents\n",
    "    db.add(spacy_doc)\n",
    "    \n",
    "    corpora.append(spacy_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check on a single recipe if the tagging process was successful\n",
    "\n",
    "#spacy_doc.has_annotation(\"TAG\") #gives True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the sentence structure of a single recipe\n",
    "\n",
    "#displacy.render(spacy_doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find out whether the ingredient in the recipe was a subject or an object\n",
    "# X was added to Y -> X is the subject, Y is the object\n",
    "\n",
    "for c in range(len(corpora)):\n",
    "\n",
    "    ingredients={}\n",
    "    indices = tagged_entities[c]\n",
    "\n",
    "    #get the name and the syntactic position\n",
    "    for token in corpora[c]:\n",
    "    \n",
    "        if 'subj' in token.dep_ or 'obj' in token.dep_:\n",
    "     \n",
    "            #if this is a chemical entity we are interested in\n",
    "            for k in indices.keys():\n",
    "                if token.text in k:\n",
    "                  \n",
    "                    #add the syntactic information\n",
    "                    indices[k] = token.dep_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In a structure \"X was added to Y\", X is the subject, i.e. the chemical being added & Y is object, i.e. the recipient\n",
    "\n",
    "def clean_results(value):\n",
    "    \n",
    "    if 'subj' in value:\n",
    "        value = 'added to mixture'\n",
    "    elif 'obj' in value:\n",
    "        value = 'recipient'\n",
    "    else:\n",
    "        value = 'order of addition unknown'\n",
    "        \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results to Questions 1.\n",
    "\n",
    "res_1=[]\n",
    "\n",
    "for i in tagged_entities:\n",
    "    ingredients = {key:clean_results(value) for (key,value) in i.items()}\n",
    "    res_1.append(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-connectivity",
   "metadata": {},
   "source": [
    "## Question 2. How much of each constituent was added?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-funds",
   "metadata": {},
   "source": [
    "### Quantities are either in brackets after the named entity (0.01 mmol, 4.28 mg), or shortly before it '2 ml dry toluene'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2=[]\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "#for each recipe\n",
    "for i,recipe in enumerate(recipes):\n",
    "    \n",
    "    res=[]\n",
    "    \n",
    "    #and each ingredient\n",
    "    for entity in tagged_entities[i].keys():\n",
    "        \n",
    "        #look for the information in brackets\n",
    "        pattern = re.compile(re.escape(entity) + r\"\\s*\\(.*?\\)\")\n",
    "        try:\n",
    "            quant = re.search(pattern, recipe).group()\n",
    "            res.append(quant)\n",
    "        \n",
    "        #tokenize and find the information preceding the entity\n",
    "        except:\n",
    "            \n",
    "            sent = ' '.join([w for w in recipe.split() if w not in sw])\n",
    "            tokenizer = TweetTokenizer()\n",
    "            wordlist = tokenizer.tokenize(sent)\n",
    "            for i,w in enumerate(wordlist):\n",
    "                if w in entities:\n",
    "                    \n",
    "                    #add the 3 words preceding the named entity\n",
    "                    res.append(' '.join([wordlist[i-3], wordlist[i-2], wordlist[i-1], wordlist[i]]))\n",
    "                    \n",
    "    res2.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-gather",
   "metadata": {},
   "source": [
    "### Question 3. Type of addition: in portions or continuous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for diagnostic phrases that inform us about the type of addition (identified in the data)\n",
    "#These will be stored in a text file so that the users of the code can edit these expressions any time\n",
    "\n",
    "os.chdir(main)\n",
    "\n",
    "with open('continuous_addition.txt', 'r+') as f:\n",
    "    cont = f.readlines()  \n",
    "    cont = [re.sub('\\n', '', c.lower()) for c in cont]\n",
    "    \n",
    "with open('addition_in_portion.txt', 'r+') as f:\n",
    "    por = f.readlines()  \n",
    "    por = [re.sub('\\n', '', p.lower()) for p in por]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(re.escape(entity) + r\"\\s*\\(.*?\\)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = []\n",
    "\n",
    "for i,recipe in enumerate(recipes):\n",
    "    \n",
    "    if any(c in recipe for c in cont) and any(p in recipe for p in por):\n",
    "        res3.append('Recipe ' + str(i+1) + ': Mention of both continuous and in-portion addition')\n",
    "        \n",
    "    elif any(c in recipe for c in cont):\n",
    "        res3.append('Recipe ' + str(i+1) + ': Continuous addition')\n",
    "        \n",
    "    elif any(p in recipe for p in por):\n",
    "        res3.append('Recipe ' + str(i+1) + ': Addition in portions')\n",
    "        \n",
    "    else:\n",
    "        res3.append('Recipe ' + str(i+1) + ': Type of addition unknown')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-bibliography",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
